{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "152ff75f-12fd-46a9-9909-f2ce19b4c01a",
    "_uuid": "ff96cdf4-4d11-4b18-a551-6ca857d504cf",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "Run on kaggle TPUv3-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "cd65808e-a990-487b-9948-d71a8f76cab6",
    "_uuid": "2fec2ff7-b08d-4abb-ac32-b1333abc82ac",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-19T12:52:43.874884Z",
     "iopub.status.busy": "2025-08-19T12:52:43.874678Z",
     "iopub.status.idle": "2025-08-19T12:52:43.882610Z",
     "shell.execute_reply": "2025-08-19T12:52:43.881622Z",
     "shell.execute_reply.started": "2025-08-19T12:52:43.874864Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '.98'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "3cecac64-d139-4863-bb8c-32ff5eb5edf1",
    "_uuid": "98529f40-0229-4766-9749-c661f4ba0f32",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-19T12:52:49.938574Z",
     "iopub.status.busy": "2025-08-19T12:52:49.938153Z",
     "iopub.status.idle": "2025-08-19T12:52:52.289045Z",
     "shell.execute_reply": "2025-08-19T12:52:52.288288Z",
     "shell.execute_reply.started": "2025-08-19T12:52:49.938534Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import jax.numpy     as jnp\n",
    "import jax.random    as random\n",
    "import jax.tree_util as jtree\n",
    "from jax import grad, jit, vmap\n",
    "from jax.sharding import Mesh, NamedSharding\n",
    "from jax.sharding import PartitionSpec as P \n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "cf816a00-ca79-4c7d-976a-d6bebafec9e2",
    "_uuid": "ccd7debe-43d7-45ec-b2a9-6f0ebd56a1b5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-19T12:52:52.290243Z",
     "iopub.status.busy": "2025-08-19T12:52:52.289864Z",
     "iopub.status.idle": "2025-08-19T12:52:53.705647Z",
     "shell.execute_reply": "2025-08-19T12:52:53.704707Z",
     "shell.execute_reply.started": "2025-08-19T12:52:52.290220Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import optax\n",
    "import flax\n",
    "from flax import nnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "d80f448b-411a-415a-9ddc-7cac6ee16fba",
    "_uuid": "35a8087f-fc08-4ab0-b9ad-e649b5d99069",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-19T12:52:53.707029Z",
     "iopub.status.busy": "2025-08-19T12:52:53.706641Z",
     "iopub.status.idle": "2025-08-19T12:52:55.956612Z",
     "shell.execute_reply": "2025-08-19T12:52:55.955619Z",
     "shell.execute_reply.started": "2025-08-19T12:52:53.707007Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5bab79ce-7796-4bd9-b03d-e6c0039ee44e",
    "_uuid": "09c187f8-a090-4683-90ba-95e2b2240e92",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-15T15:55:26.732587Z",
     "iopub.status.busy": "2025-08-15T15:55:26.732239Z",
     "iopub.status.idle": "2025-08-15T15:55:26.742201Z",
     "shell.execute_reply": "2025-08-15T15:55:26.738082Z",
     "shell.execute_reply.started": "2025-08-15T15:55:26.732562Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 384 # 上下文長度 / Context window size\n",
    "EMBED_DIM = 256 # 嵌入維度 / Embedding dimension\n",
    "QKV_DIM = 64 # QKV 向量維度 / QKV feature dimension\n",
    "HEAD_SIZE = 4 # 注意力頭數 / Number of attention heads\n",
    "BLOCK_SIZE = 8 # 解碼器模塊數 / Number of decoder blocks\n",
    "\n",
    "MICRO_BATCH_SIZE = 16 # Batch size per iter \n",
    "GLOBAL_BATCH_SIZE = 32 # Batch size per step \n",
    "\n",
    "LEARING_RATE = 1e-6\n",
    "MOMENTUM = 0.9 # Momentum factor for optimizer\n",
    "\n",
    "DATASET = \"minipile\" # \"toy\" or \"openwebtext\" or \"minipile\"\n",
    "\n",
    "train_steps = 5000\n",
    "eval_every = 100\n",
    "\n",
    "# Assertion to ensure attention dimensions match\n",
    "assert QKV_DIM*HEAD_SIZE == EMBED_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a195eccc-af52-468a-ae93-edbb6be6e6aa",
    "_uuid": "7607913f-d63b-4135-9e47-2fce83cf4ba5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-15T15:55:26.745638Z",
     "iopub.status.busy": "2025-08-15T15:55:26.745273Z",
     "iopub.status.idle": "2025-08-15T15:55:29.098905Z",
     "shell.execute_reply": "2025-08-15T15:55:29.093950Z",
     "shell.execute_reply.started": "2025-08-15T15:55:26.745611Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# List all local JAX devices (TPU cores)\n",
    "jax.local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "43722db3-6a45-4950-aa7d-bbb62949e023",
    "_uuid": "e73fe492-5d79-433e-a878-f20bf7956b2f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-15T15:55:29.101983Z",
     "iopub.status.busy": "2025-08-15T15:55:29.101638Z",
     "iopub.status.idle": "2025-08-15T15:55:29.217607Z",
     "shell.execute_reply": "2025-08-15T15:55:29.212545Z",
     "shell.execute_reply.started": "2025-08-15T15:55:29.101956Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# TPU device mesh and Sharding strategy for tensor/model parallelism\n",
    "\n",
    "# Number of available TPU cores\n",
    "num_device = len(jax.local_devices()) \n",
    "\n",
    "# Create a mesh with axis names for logical partitioning\n",
    "mesh = Mesh(devices=np.array(jax.devices()).reshape(1, num_device),axis_names=('data', 'model')) \n",
    "\n",
    "# Setup sharding strategy for dataset across the mesh\n",
    "data_sharding = NamedSharding(mesh, P())\n",
    "\n",
    "# pseudo random number generator's key\n",
    "key = random.PRNGKey(777) # random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "488bc41a-be4b-4ab2-bb93-c8a03f2f37e4",
    "_uuid": "f613681e-7711-43c3-8634-180e8532c7bb",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5ae06a2d-dc97-4e08-b236-f619baf2d7a9",
    "_uuid": "19976a64-5e2d-44df-be32-07fe30196383",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-15T15:55:29.220084Z",
     "iopub.status.busy": "2025-08-15T15:55:29.219835Z",
     "iopub.status.idle": "2025-08-15T15:55:32.876179Z",
     "shell.execute_reply": "2025-08-15T15:55:32.870729Z",
     "shell.execute_reply.started": "2025-08-15T15:55:29.220061Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "if DATASET == \"openwebtext\":\n",
    "    file_path = \"/kaggle/input/openwebtext-dataset/train_split.txt\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = []\n",
    "        for line in tqdm(f, desc=\"Loading OpenWebText\", unit=\" lines\"):\n",
    "            lines.append(line)\n",
    "            \n",
    "    print(\"Openwebtext loaded.\")\n",
    "\n",
    "elif DATASET == \"minipile\":\n",
    "\n",
    "    ds = load_dataset(\"JeanKaddour/minipile\")\n",
    "\n",
    "    print(f\"資料集總筆數: {len(ds)}\")\n",
    "    print(\"MiniPile loaded.\")\n",
    "    \n",
    "else:\n",
    "    pass\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"經過的時間: {end_time - start_time:.2f} 秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ed434f3f-172d-401c-bd69-f79e7d64d305",
    "_uuid": "2dd553d6-9f80-4e67-8b5f-e5297e99e898",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-15T15:55:32.879005Z",
     "iopub.status.busy": "2025-08-15T15:55:32.877999Z",
     "iopub.status.idle": "2025-08-15T15:55:32.891511Z",
     "shell.execute_reply": "2025-08-15T15:55:32.886071Z",
     "shell.execute_reply.started": "2025-08-15T15:55:32.878979Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Preview Sample Data\n",
    "ds[\"train\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "58e16f22-e660-4b17-ad46-ef3ec4aa4bdc",
    "_uuid": "ddd1f4b5-ff57-4d84-9a35-1ac8068cc9f1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-15T15:55:32.893768Z",
     "iopub.status.busy": "2025-08-15T15:55:32.893469Z",
     "iopub.status.idle": "2025-08-15T15:57:05.500047Z",
     "shell.execute_reply": "2025-08-15T15:57:05.495795Z",
     "shell.execute_reply.started": "2025-08-15T15:55:32.893729Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Vocabulary Encoding / Decoding \n",
    "\n",
    "def build_vocabulary(dataset):\n",
    "    \"\"\"從資料集中建立字元詞彙表\"\"\"\n",
    "    char_set = set()\n",
    "    print(\"正在從資料集建立詞彙表...\")\n",
    "    for example in tqdm(dataset['train'], desc=\"掃描字元\"):\n",
    "        char_set.update(example['text'])\n",
    "\n",
    "    # 加入特殊符號\n",
    "    # <<pad>>: 填充符號 Padding\n",
    "    # <<eos>>: 序列結束符號 End-of-Sequence\n",
    "    # <<sos>>: 序列開始符號 Start-of-Sequence (here ignore)\n",
    "    # <<unk>>: 未知字元 Unknown\n",
    "    special_tokens = [\"<<pad>>\", \"<<eos>>\", \"<<unk>>\"]\n",
    "    sorted_chars = sorted(list(char_set))\n",
    "    \n",
    "    return special_tokens + sorted_chars\n",
    "\n",
    "\n",
    "chars = build_vocabulary(ds)\n",
    "vocab_size = len(chars)\n",
    "\n",
    "# Character-to-index and index-to-character mappings\n",
    "ctoi = { c:i for i, c in enumerate(chars) }\n",
    "itoc = { i:c for c, i in ctoi.items() } \n",
    "\n",
    "PAD_IDX = ctoi[\"<<pad>>\"]\n",
    "EOS_IDX = ctoi[\"<<eos>>\"]\n",
    "UNK_IDX = ctoi[\"<<unk>>\"]\n",
    "\n",
    "encode = lambda s: [ctoi.get(c, ctoi[\"<<unk>>\"]) for c in s]\n",
    "decode = lambda l: \"\".join([itoc[i] for i in l])\n",
    "\n",
    "print(f\"{vocab_size=}\")\n",
    "print(f\"(PAD_IDX): {PAD_IDX}, (EOS_IDX): {EOS_IDX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f9dd6976-3830-4812-8a7a-ca40eab18acd",
    "_uuid": "3284b225-eff5-4a64-a4ad-f8f9e0b5d436",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-15T15:57:05.502819Z",
     "iopub.status.busy": "2025-08-15T15:57:05.502218Z",
     "iopub.status.idle": "2025-08-15T15:57:05.512029Z",
     "shell.execute_reply": "2025-08-15T15:57:05.507724Z",
     "shell.execute_reply.started": "2025-08-15T15:57:05.502794Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Encoding Validation\n",
    "sample_text = \"Hello World\"\n",
    "print(encode(sample_text))\n",
    "print(decode(encode(sample_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0da212c0-5a56-4394-8c73-cc81461a3c93",
    "_uuid": "7f7b9c70-4e1b-467e-9d3a-c103d0a305f1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-15T15:57:05.514717Z",
     "iopub.status.busy": "2025-08-15T15:57:05.514471Z",
     "iopub.status.idle": "2025-08-15T15:57:05.528460Z",
     "shell.execute_reply": "2025-08-15T15:57:05.524352Z",
     "shell.execute_reply.started": "2025-08-15T15:57:05.514660Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_batch_generator(key, dataset, batch_size, context_size, eos_idx, pad_idx):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    n_samples = len(dataset)\n",
    "    \n",
    "    while True:\n",
    "        key, subkey = random.split(key)\n",
    "        indices = random.choice(subkey, n_samples, shape=(batch_size,), replace=False)\n",
    "        \n",
    "        batch_x, batch_y, batch_mask = [], [], []\n",
    "        \n",
    "        for idx in indices:\n",
    "            text = dataset[int(idx)]['text']\n",
    "            encoded_content = encode(text)\n",
    "\n",
    "            # --- 核心邏輯：區分截斷與否 ---\n",
    "            \n",
    "            # 情況 1: 序列被截斷 (原始文本比 context_size 長)\n",
    "            if len(encoded_content) > context_size  :\n",
    "                x = encoded_content[:context_size]\n",
    "                y = encoded_content[1:context_size + 1]\n",
    "                mask = [1] * context_size\n",
    "\n",
    "            # 情況 2: 序列正常結束 (原始文本剛好)\n",
    "            elif  len(encoded_content) == context_size:\n",
    "                x = encoded_content\n",
    "                y = encoded_content[1:context_size] + [eos_idx]\n",
    "                mask = [1] * context_size\n",
    "            \n",
    "            # 情況 3: 序列正常結束 (原始文本較短)\n",
    "            else:\n",
    "                # 1. 在內容後加上 EOS\n",
    "                content_with_eos = encoded_content + [eos_idx]\n",
    "                \n",
    "                # 2. 建立輸入 x (填充到 context_size)\n",
    "                x = content_with_eos + [pad_idx] * (context_size - len(content_with_eos))\n",
    "                \n",
    "                # 3. 建立標籤 y\n",
    "                # 標籤是 x 向左位移一格\n",
    "                y = x[1:] + [pad_idx]\n",
    "                \n",
    "                # 4. 建立遮罩 (只標示非 PAD 位置)\n",
    "                mask = [1] * len(content_with_eos) + [0] * (context_size - len(content_with_eos))\n",
    "\n",
    "            batch_x.append(x)\n",
    "            batch_y.append(y)\n",
    "            batch_mask.append(mask)\n",
    "\n",
    "        yield (jnp.array(batch_x, dtype=jnp.int32),\n",
    "               jnp.array(batch_y, dtype=jnp.int32),\n",
    "               jnp.array(batch_mask, dtype=jnp.int32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T15:57:05.530828Z",
     "iopub.status.busy": "2025-08-15T15:57:05.530575Z",
     "iopub.status.idle": "2025-08-15T15:57:05.916569Z",
     "shell.execute_reply": "2025-08-15T15:57:05.911116Z",
     "shell.execute_reply.started": "2025-08-15T15:57:05.530806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "context_size = 5\n",
    "batch_size = 4 \n",
    "\n",
    "# 建立一個 mock 資料集，精確對應三個邏輯分支\n",
    "mock_dataset = [\n",
    "    {'text': '123456'},  # 情境 1: > context_size (過長)\n",
    "    {'text': '12345'},   # 情境 2: == context_size (剛好)\n",
    "    {'text': '1234'},    # 情境 3: < context_size (過短)\n",
    "    {'text': '123'},     # 情境 4: < context_size (過短)\n",
    "]\n",
    "                \n",
    "print(\"--- 開始測試 ---\")\n",
    "print(f\"Context Size: {context_size}, PAD Index: {PAD_IDX}, EOS Index: {EOS_IDX}\\n\")\n",
    "\n",
    "# 建立生成器\n",
    "mock_generator = create_batch_generator(\n",
    "    random.PRNGKey(0), mock_dataset, batch_size, context_size, EOS_IDX, PAD_IDX\n",
    ")\n",
    "\n",
    "# 取得一批測試資料\n",
    "\n",
    "\n",
    "# --- 測試分析 ---\n",
    "for i in mock_dataset:\n",
    "    x, y, mask = next(create_batch_generator(\n",
    "        random.PRNGKey(0), [i], 1, context_size, EOS_IDX, PAD_IDX\n",
    "    ))\n",
    "    print(f\"輸出 x: {x}\")\n",
    "\n",
    "    print(f\"輸出 y: {y}\")\n",
    "\n",
    "    print(f\"輸出 mask: {mask}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "88883dcf-20d6-4a57-918f-50db94522e0f",
    "_uuid": "43341516-27a8-417f-9af1-a94ec741c664",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "68b3be35-8e26-414c-9bcf-66361d290a31",
    "_uuid": "06c8bc21-775d-4b33-b66a-9f1dd10a6d5f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-15T15:57:05.919203Z",
     "iopub.status.busy": "2025-08-15T15:57:05.918951Z",
     "iopub.status.idle": "2025-08-15T15:57:05.929903Z",
     "shell.execute_reply": "2025-08-15T15:57:05.924114Z",
     "shell.execute_reply.started": "2025-08-15T15:57:05.919178Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"vocab_size\": vocab_size,\n",
    "    \"context_size\": CONTEXT_SIZE,\n",
    "    \"embed_dim\": EMBED_DIM,\n",
    "    \"qkv_dim\": QKV_DIM,\n",
    "    \"head_size\": HEAD_SIZE,\n",
    "    \"block_size\": BLOCK_SIZE,\n",
    "    \"activation\": \"gelu\",\n",
    "    \"ffn_d\": EMBED_DIM*4,\n",
    "    \"dropout\": 0.2,\n",
    "    \"mask_pad\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "45149bdb-984a-44d3-905a-65015a69e571",
    "_uuid": "954a2f90-f2b5-49ca-8a8f-cc19bd7966ea",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-15T15:57:05.932154Z",
     "iopub.status.busy": "2025-08-15T15:57:05.931912Z",
     "iopub.status.idle": "2025-08-15T15:57:05.948199Z",
     "shell.execute_reply": "2025-08-15T15:57:05.944217Z",
     "shell.execute_reply.started": "2025-08-15T15:57:05.932135Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MaskedSelfAttention(nnx.Module):\n",
    "    def __init__(self, config: dict, rngs: nnx.Rngs):\n",
    "        init_fn = nnx.initializers.lecun_normal()\n",
    "        \n",
    "        assert config[\"embed_dim\"] == config[\"head_size\"] * config[\"qkv_dim\"]\n",
    "        self.qkv_feature = config[\"qkv_dim\"]\n",
    "        self.num_heads = config[\"head_size\"]\n",
    "        self.mask_pad = config[\"mask_pad\"] # pad number in mask\n",
    "        \n",
    "        self.qkv_proj = nnx.Linear(in_features=config[\"embed_dim\"], out_features=config[\"embed_dim\"]*3, \n",
    "                                   kernel_init=nnx.with_partitioning(init_fn, (None, 'model')),\n",
    "                                   dtype=jnp.bfloat16, param_dtype=jnp.bfloat16, rngs=rngs)\n",
    "        self.output_proj = nnx.Linear(in_features=config[\"embed_dim\"], out_features=config[\"embed_dim\"], \n",
    "                                      kernel_init=nnx.with_partitioning(init_fn, ('model', None)),\n",
    "                                      dtype=jnp.bfloat16, param_dtype=jnp.bfloat16, rngs=rngs)\n",
    "        self.dropout = nnx.Dropout(config[\"dropout\"], rngs=rngs)\n",
    "\n",
    "    @nnx.remat \n",
    "    def __call__(self, x: jax.Array, masks: jax.Array):\n",
    "        B, S, E = x.shape # (batch_size, seq_len, embed_dim)\n",
    "        B_mask, S_mask = masks.shape # (batch_size, seq_len)\n",
    "        \n",
    "        assert B == B_mask and S == S_mask\n",
    "        \n",
    "        x = jax.lax.with_sharding_constraint(x, P())\n",
    "        \n",
    "        # (batch_size, seq_len, embed_dim) -> (batch_size, seq_len, 3 * qkv_dim * num_heads) , embed_dim = qkv_dim * num_heads\n",
    "        qkv = self.qkv_proj(x) \n",
    "        \n",
    "        # (batch_size, num_heads, seq_len, 3 * qkv_dim)\n",
    "        qkv = qkv.reshape(B, S , self.num_heads, self.qkv_feature * 3 ).transpose(0, 2, 1, 3)      \n",
    "        \n",
    "        q, k, v = jnp.array_split(qkv, 3, axis=-1)\n",
    "\n",
    "        # (QK^T / sqrt(d_k))\n",
    "        # (batch, num_heads, seq_len, qkv_dim) @ (batch, num_heads, qkv_dim, seq_len) -> (batch, num_heads, seq_len, seq_len)\n",
    "        scores = jnp.matmul(q, k.transpose(0, 1, 3, 2)) / jnp.sqrt(self.qkv_feature)\n",
    "\n",
    "        # Attention Mask\n",
    "        causal_mask = jnp.triu(jnp.ones((S, S), dtype=jnp.bool_), k=1)[None,None,:,:]\n",
    "        padding_mask = (masks == self.mask_pad)[:, None, None, :]  \n",
    "        attention_mask = jnp.logical_or(causal_mask, padding_mask) # combine masks\n",
    "        # Apply mask\n",
    "        large_negative = jnp.finfo(scores.dtype).min\n",
    "        scores = jnp.where(attention_mask, large_negative, scores) \n",
    "        \n",
    "        # Attetion weights\n",
    "        attn_weights = nnx.softmax(scores, axis=-1)\n",
    "\n",
    "        # (batch, num_heads, seq_len, seq_len) @ (batch, num_heads, seq_len, qkv_dim) -> (batch, num_heads, seq_len, qkv_dim)\n",
    "        attn_output = jnp.matmul(attn_weights, v)\n",
    "\n",
    "        # (batch, num_heads, seq_len, qkv_dim) -> (batch, seq_len, num_heads, qkv_dim) -> (batch, seq_len, embed_dim)\n",
    "        attn_output = attn_output.transpose(0, 2, 1, 3).reshape(B, S, E)\n",
    "\n",
    "        attn_output = jax.lax.with_sharding_constraint(attn_output, P(None, None, 'model'))\n",
    "        \n",
    "        output = self.output_proj(attn_output)\n",
    "\n",
    "        x = jax.lax.with_sharding_constraint(x, P(None, 'model', None))\n",
    "        output = self.dropout(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "51348157-59e3-439f-8e8b-92de57250c85",
    "_uuid": "ace94e38-fcc3-4487-9ade-916fb5e373c7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-15T15:57:05.951064Z",
     "iopub.status.busy": "2025-08-15T15:57:05.950403Z",
     "iopub.status.idle": "2025-08-15T15:57:05.963645Z",
     "shell.execute_reply": "2025-08-15T15:57:05.959010Z",
     "shell.execute_reply.started": "2025-08-15T15:57:05.951038Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GPTFeedForwardNetwork(nnx.Module):\n",
    "    def __init__(self, config: dict, rngs: nnx.Rngs):\n",
    "        init_fn = nnx.initializers.lecun_normal()\n",
    "\n",
    "        self.layer1 = nnx.Linear(in_features=config[\"embed_dim\"], out_features=config[\"ffn_d\"], \n",
    "                                 kernel_init=nnx.with_partitioning(init_fn, (None, 'model')),\n",
    "                                 dtype=jnp.bfloat16, param_dtype=jnp.bfloat16, rngs=rngs)\n",
    "        self.layer2 = nnx.Linear(in_features=config[\"ffn_d\"], out_features=config[\"embed_dim\"],\n",
    "                                 kernel_init=nnx.with_partitioning(init_fn, ('model', None)),\n",
    "                                 dtype=jnp.bfloat16, param_dtype=jnp.bfloat16, rngs=rngs)\n",
    "        \n",
    "        self.activation = {\n",
    "            'relu':nnx.relu,\n",
    "            'swish':nnx.swish,\n",
    "            'gelu':nnx.gelu\n",
    "        }[config[\"activation\"]]\n",
    "        \n",
    "        self.dropout = nnx.Dropout(config[\"dropout\"], rngs=rngs)\n",
    "\n",
    "    @nnx.remat \n",
    "    def __call__(self, x: jax.Array):\n",
    "        x = jax.lax.with_sharding_constraint(x, P())\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x) \n",
    "        x = self.layer2(x)\n",
    "        x = jax.lax.with_sharding_constraint(x, P(None, 'model', None))\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3db43add-069a-4d2b-93be-b5b469c091e2",
    "_uuid": "86d36d3c-6feb-45ce-b2c6-fcb1d0dc04d7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-15T15:57:05.965308Z",
     "iopub.status.busy": "2025-08-15T15:57:05.965087Z",
     "iopub.status.idle": "2025-08-15T15:57:05.978321Z",
     "shell.execute_reply": "2025-08-15T15:57:05.972849Z",
     "shell.execute_reply.started": "2025-08-15T15:57:05.965288Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GPTDecoderBlock(nnx.Module):\n",
    "    def __init__(self, config: dict, rngs: nnx.Rngs):\n",
    "\n",
    "        self.atn = MaskedSelfAttention(config, rngs)\n",
    "        self.norm1 = nnx.LayerNorm(num_features=config[\"embed_dim\"],\n",
    "                                   dtype=jnp.bfloat16, param_dtype=jnp.bfloat16, rngs=rngs)\n",
    "        self.ffn = GPTFeedForwardNetwork(config, rngs)\n",
    "        self.norm2 = nnx.LayerNorm(num_features=config[\"embed_dim\"], \n",
    "                                   dtype=jnp.bfloat16, param_dtype=jnp.bfloat16, rngs=rngs)\n",
    "\n",
    "    # Enable activation recomputation to reduce memory usage \n",
    "    @nnx.remat  \n",
    "    def __call__(self, x: jax.Array, padding_masks : jax.Array):\n",
    "        x = x + self.atn(self.norm1(x), padding_masks)\n",
    "        x = x + self.ffn(self.norm2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "968dab4c-7ee6-45ce-8dce-94fe44dabf88",
    "_uuid": "b25c2912-71e6-4139-96dd-be0bdb15a8f5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-15T15:57:05.979184Z",
     "iopub.status.busy": "2025-08-15T15:57:05.978997Z",
     "iopub.status.idle": "2025-08-15T15:57:05.996146Z",
     "shell.execute_reply": "2025-08-15T15:57:05.990707Z",
     "shell.execute_reply.started": "2025-08-15T15:57:05.979166Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GPT(nnx.Module):\n",
    "    def __init__(self, config: dict, rngs: nnx.Rngs):\n",
    "        init_fn = nnx.initializers.lecun_normal()\n",
    "        params_key = rngs.params() \n",
    "        split_keys = jax.random.split(params_key, config[\"block_size\"])\n",
    "\n",
    "        # token embedding and positional embedding shared embedding\n",
    "        self.embeding = nnx.Embed(num_embeddings=config[\"vocab_size\"]+config[\"context_size\"], features=config[\"embed_dim\"]\n",
    "                                  , dtype=jnp.bfloat16, param_dtype=jnp.bfloat16, rngs=rngs)\n",
    "        self.blocks = self.blocks_create(config, split_keys)\n",
    "        self.norm = nnx.LayerNorm(num_features=config[\"embed_dim\"],\n",
    "                                  dtype=jnp.bfloat16, param_dtype=jnp.bfloat16, rngs=rngs)\n",
    "        self.linear_proj = nnx.Linear(in_features=config[\"embed_dim\"], out_features=config[\"vocab_size\"], \n",
    "                                      kernel_init=nnx.with_partitioning(init_fn, (None, None)),\n",
    "                                      dtype=jnp.bfloat16, param_dtype=jnp.bfloat16, rngs=rngs)\n",
    "        \n",
    "        \n",
    "    def __call__(self, input_data: jax.Array, padding_masks : jax.Array):\n",
    "            \n",
    "        n_batch, n_contxt = input_data.shape # (Batch, Seq)\n",
    "\n",
    "        # shift postion for embeding\n",
    "        position = jnp.arange(config[\"vocab_size\"], config[\"vocab_size\"]+config[\"context_size\"], dtype=jnp.int32)\n",
    "        position = jnp.repeat(position[None, :], n_batch, axis=0)\n",
    "\n",
    "        # Create array for two embeddings\n",
    "        x = jnp.zeros((n_batch, config[\"context_size\"], 2), dtype=jnp.int32)\n",
    "        x = x.at[:, :, 0].set(input_data)  \n",
    "        x = x.at[:, :, 1].set(position)  \n",
    "        x = self.embeding(x)\n",
    "        \n",
    "        # Summing over embedding axis (token + position)\n",
    "        x = jnp.sum(x, axis=-2) # Reduce postion embeding vector and token embeding vector\n",
    "        \n",
    "        x = jax.lax.with_sharding_constraint(x, P(None, 'model', None))\n",
    "        \n",
    "        # Blocks\n",
    "        x = GPT.blocks_forward(self.blocks, x, padding_masks)\n",
    "\n",
    "        # Last norm\n",
    "        x = self.norm(x) \n",
    "\n",
    "        x = jax.lax.with_sharding_constraint(x, P())\n",
    "        # Last layer\n",
    "        logits = self.linear_proj(x)\n",
    "        \n",
    "        return logits \n",
    "\n",
    "    @nnx.vmap(in_axes=(None, None, 0), out_axes=0,)\n",
    "    def blocks_create(self, config, key: jax.Array):\n",
    "      return GPTDecoderBlock(config, nnx.Rngs(key))\n",
    "\n",
    "    @nnx.scan(in_axes=(0, nnx.Carry, None), out_axes=nnx.Carry,)\n",
    "    def blocks_forward(block, x, masks):\n",
    "        x = block(x, masks)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b2546d7c-d283-48ac-8851-d862f78f0bbc",
    "_uuid": "9555c5aa-912b-4a74-ac41-cfbc9c7afcdd",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Loss Function and Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T15:57:05.997923Z",
     "iopub.status.busy": "2025-08-15T15:57:05.997714Z",
     "iopub.status.idle": "2025-08-15T15:57:06.008001Z",
     "shell.execute_reply": "2025-08-15T15:57:06.003053Z",
     "shell.execute_reply.started": "2025-08-15T15:57:05.997903Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def loss_fn(model, data_inputs, masks, labels):\n",
    "  \"\"\"Forward pass loss computation.\"\"\"\n",
    "  logits = model(data_inputs, masks).astype(jnp.float32)\n",
    "    \n",
    "  mask = (labels != PAD_IDX)\n",
    "    \n",
    "  losses = optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=labels)\n",
    "  mean_loss = jnp.sum(losses * mask) / jnp.sum(mask)\n",
    "  return mean_loss, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "22f125a8-7d3b-4059-b184-e28f2637d186",
    "_uuid": "00a41880-747c-43c1-9991-7689d0e0f130",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-15T15:57:06.009972Z",
     "iopub.status.busy": "2025-08-15T15:57:06.009743Z",
     "iopub.status.idle": "2025-08-15T15:57:06.024306Z",
     "shell.execute_reply": "2025-08-15T15:57:06.020258Z",
     "shell.execute_reply.started": "2025-08-15T15:57:06.009950Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "grad_fnc = nnx.jit(nnx.value_and_grad(loss_fn, has_aux=True))\n",
    "\n",
    "def train_step(model, optimizer: nnx.Optimizer, metrics: nnx.MultiMetric, x, mask ,y, x_stack, mask_stack, y_stack, pad_index):\n",
    "    \"\"\"Train step with gradient accumulation over x, x_stack / y, y_stack.\"\"\"\n",
    "\n",
    "    micro_batch_num =  x_stack.shape[0] + 1\n",
    "    \n",
    "    # First forward-backward pass\n",
    "    (loss, logits), grads = grad_fnc(model, x, mask, y)\n",
    "    accum_grads = grads\n",
    "    total_loss = loss\n",
    "    logits_list = [logits]\n",
    "    y_list = [y]\n",
    "\n",
    "    # Accumulate over stacked microbatches\n",
    "    for x, mask, y in zip(x_stack, mask_stack, y_stack):\n",
    "        (loss, logits), grads = grad_fnc(model, x, mask, y)\n",
    "\n",
    "        total_loss += loss\n",
    "\n",
    "        accum_grads = jtree.tree_map(lambda ag, g: ag + g, accum_grads, grads)\n",
    "\n",
    "        logits_list.append(logits)\n",
    "        y_list.append(y)\n",
    "\n",
    "    # Average accumulated gradient\n",
    "    accum_grads = jtree.tree_map(lambda g: g / micro_batch_num, accum_grads)\n",
    "\n",
    "    # Optimizer update\n",
    "    optimizer.update(accum_grads)   \n",
    "    \n",
    "    # Trace train loss and accuarcy\n",
    "    logits = jnp.reshape(jnp.concatenate(logits_list, axis=0), (-1, logits_list[0].shape[-1]))\n",
    "    labels = jnp.reshape(jnp.concatenate(y_list, axis=0), (-1,))\n",
    "\n",
    "    metrics.update(\n",
    "        loss=total_loss / len(logits_list),\n",
    "        logits=logits[(labels != pad_index)],\n",
    "        labels=labels[(labels != pad_index)],\n",
    "    )\n",
    "    \n",
    "    \n",
    "def eval_step(model, metrics: nnx.MultiMetric, x, masks, y, pad_index):\n",
    "    \"\"\"Evaluation step for validation.\"\"\"\n",
    "    loss, logits = loss_fn(model, x, masks, y)\n",
    "\n",
    "    logits = jnp.reshape(jnp.concatenate(logits, axis=0), (-1, logits.shape[-1]))\n",
    "    labels = jnp.reshape(jnp.concatenate(y, axis=0), (-1,))\n",
    "    \n",
    "    metrics.update(loss=loss, logits=logits[(labels != pad_index)], labels=labels[(labels != pad_index)])  # In-place updates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8f04d4bd-91d8-4ff6-8ec0-73b7f806d59d",
    "_uuid": "0379cb1c-b5ca-46bf-966e-1246889507e7",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Model Sharding and Parallelism\n",
    "This section handles model partitioning across TPU devices using JAX sharding constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8fdb1baa-032d-49ad-b77d-afdbec8a5beb",
    "_uuid": "258f1a3c-325d-48cf-8063-bd9c04d187a5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-15T15:57:06.026444Z",
     "iopub.status.busy": "2025-08-15T15:57:06.026002Z",
     "iopub.status.idle": "2025-08-15T15:57:06.036748Z",
     "shell.execute_reply": "2025-08-15T15:57:06.032831Z",
     "shell.execute_reply.started": "2025-08-15T15:57:06.026420Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@nnx.jit(static_argnames=[\"mesh\"])\n",
    "def create_sharded_model(mesh):\n",
    "  with mesh:  \n",
    "      model = GPT(config, rngs=nnx.Rngs(99)) # Unsharded at this moment.\n",
    "      state = nnx.state(model)               # The model's state, a pure pytree.\n",
    "      pspecs = nnx.get_partition_spec(state)    \n",
    "      sharded_state = jax.lax.with_sharding_constraint(state, pspecs)\n",
    "      nnx.update(model, sharded_state)       # The model is sharded now!\n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c99a11ba-7b86-40a0-9682-61ab1c3a7bb6",
    "_uuid": "829ee837-bcd3-49b1-b8e9-96c77b4eda0f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-15T15:57:06.038966Z",
     "iopub.status.busy": "2025-08-15T15:57:06.038753Z",
     "iopub.status.idle": "2025-08-15T15:57:41.241547Z",
     "shell.execute_reply": "2025-08-15T15:57:41.238102Z",
     "shell.execute_reply.started": "2025-08-15T15:57:06.038947Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model = create_sharded_model(mesh)\n",
    "except Exception as e:\n",
    "    print(f\"error: {e}\")\n",
    "\n",
    "model.train()\n",
    "optimizer = nnx.Optimizer(model, optax.adamw(LEARING_RATE, MOMENTUM))\n",
    "metrics = nnx.MultiMetric(\n",
    "    accuracy=nnx.metrics.Accuracy(),\n",
    "    loss=nnx.metrics.Average('loss'),\n",
    ")\n",
    "\n",
    "train_generator = create_batch_generator(\n",
    "    random.PRNGKey(0), ds[\"train\"], MICRO_BATCH_SIZE, CONTEXT_SIZE, EOS_IDX, PAD_IDX\n",
    ")\n",
    "val_generator = create_batch_generator(\n",
    "    random.PRNGKey(1), ds[\"validation\"], MICRO_BATCH_SIZE, CONTEXT_SIZE, EOS_IDX, PAD_IDX\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d3ca43b1-3dc7-4f50-a28f-733069e898fd",
    "_uuid": "13eb2389-e266-4222-8069-5175bf6f5cd3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-15T15:57:41.246142Z",
     "iopub.status.busy": "2025-08-15T15:57:41.245614Z",
     "iopub.status.idle": "2025-08-15T15:57:42.432316Z",
     "shell.execute_reply": "2025-08-15T15:57:42.428106Z",
     "shell.execute_reply.started": "2025-08-15T15:57:41.246118Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "nnx.display(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ecfe0ec8-b932-4695-905e-2c689fc21162",
    "_uuid": "1dfd19a0-2e2d-415b-a999-85329d725b42",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "181f4cc4-063f-4aaf-89c0-037d5cadea7f",
    "_uuid": "361b38fc-631e-4ecd-a1c8-737c323d1e3c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-15T15:57:42.435306Z",
     "iopub.status.busy": "2025-08-15T15:57:42.435090Z",
     "iopub.status.idle": "2025-08-15T16:40:38.359005Z",
     "shell.execute_reply": "2025-08-15T16:40:38.353024Z",
     "shell.execute_reply.started": "2025-08-15T15:57:42.435285Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ---- Real-time plotting ----\n",
    "\n",
    "metrics_history = {\n",
    "    'train_loss': [],\n",
    "    'train_accuracy': [],\n",
    "    'test_loss': [],\n",
    "    'test_accuracy': [],\n",
    "    'steps': [] \n",
    "}\n",
    "\n",
    "def get_subkeys(key):\n",
    "    keys = random.split(key, GLOBAL_BATCH_SIZE // MICRO_BATCH_SIZE + 1)\n",
    "    return keys[0], keys[1:]\n",
    "\n",
    "\n",
    "with mesh:\n",
    "    # Main training loop\n",
    "    for step in tqdm(range(train_steps)):\n",
    "        \n",
    "        # Load data for the first micro-batch and stacked micro-batches for gradient accumulation\n",
    "        key, subkeys = get_subkeys(key) \n",
    "        x, y, masks = next(train_generator)\n",
    "        xs, ys, maskss = zip(*(next(train_generator) for k in subkeys[1:]))\n",
    "        x_stack, y_stack, masks_stack = jnp.stack(xs), jnp.stack(ys), jnp.stack(maskss)\n",
    "        train_step(model, optimizer, metrics, x, masks, y, x_stack, masks_stack, y_stack, PAD_IDX)\n",
    "\n",
    "        # Periodic evaluation and metric logging\n",
    "        if step > 0 and (step % eval_every == 0 or step == train_steps - 1):  \n",
    "            # Log the training metrics.\n",
    "            for metric, value in metrics.compute().items():  # Compute the metrics.\n",
    "                metrics_history[f'train_{metric}'].append(value)  # Record the metrics.\n",
    "            metrics.reset()  # Reset the metrics for the test set.\n",
    "    \n",
    "            # Compute the metrics on the validation set \n",
    "            for _ in range(GLOBAL_BATCH_SIZE // MICRO_BATCH_SIZE):\n",
    "                x, y, masks = next(val_generator)\n",
    "                eval_step(model, metrics, x, masks, y, PAD_IDX)\n",
    "    \n",
    "            # Log the test metrics.\n",
    "            for metric, value in metrics.compute().items():\n",
    "                metrics_history[f'test_{metric}'].append(value)\n",
    "            metrics.reset()  # Reset the metrics \n",
    "    \n",
    "            # Record the step number for the x-axis\n",
    "            metrics_history['steps'].append(step)\n",
    "            \n",
    "            # --- Update the plot for Kaggle ---\n",
    "            # Clear previous output and redraw plots for live update\n",
    "            clear_output(wait=True) # Clear the previous output of the storage cell, wait=True to avoid flickering\n",
    "\n",
    "            print(\n",
    "              f\"[train] step: {step}, \"\n",
    "              f\"loss: {metrics_history['train_loss'][-1]}, \"\n",
    "              f\"accuracy: {metrics_history['train_accuracy'][-1] * 100}\"\n",
    "            )\n",
    "            print(\n",
    "              f\"[test] step: {step}, \"\n",
    "              f\"loss: {metrics_history['test_loss'][-1]}, \"\n",
    "              f\"accuracy: {metrics_history['test_accuracy'][-1] * 100}\"\n",
    "            )\n",
    "            \n",
    "            # Recreate the chart and axes each time\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "            ax1.set_title('Loss')\n",
    "            ax1.set_xlabel('Training Step')\n",
    "            ax1.set_ylabel('Loss')\n",
    "            ax2.set_title('Accuracy')\n",
    "            ax2.set_xlabel('Training Step')\n",
    "            ax2.set_ylabel('Accuracy (%)')\n",
    "    \n",
    "            ax1.plot(metrics_history['steps'], metrics_history['train_loss'], 'r-', label='train_loss')\n",
    "            ax1.plot(metrics_history['steps'], metrics_history['test_loss'], 'b-', label='test_loss')\n",
    "            ax2.plot(metrics_history['steps'], [acc * 100 for acc in metrics_history['train_accuracy']], 'r-', label='train_accuracy')\n",
    "            ax2.plot(metrics_history['steps'], [acc * 100 for acc in metrics_history['test_accuracy']], 'b-', label='test_accuracy')\n",
    "    \n",
    "            ax1.legend()\n",
    "            ax2.legend()\n",
    "            plt.tight_layout() # Adjust layout to avoid overlap\n",
    "            display(fig) # Display the chart in the Notebook\n",
    "            plt.close(fig) # Close the chart object to free up memory and avoid displaying it twice\n",
    "\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "efb327da-b923-4b7d-98e5-77223ae5bba4",
    "_uuid": "c8b05251-16bb-4506-b5b7-ee65deb73a8b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e3054a84-6239-4869-99c3-d0935bb55ad7",
    "_uuid": "ad6c078f-5b2d-4e9d-b89e-70fc17166a2d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-15T16:40:38.361341Z",
     "iopub.status.busy": "2025-08-15T16:40:38.361116Z",
     "iopub.status.idle": "2025-08-15T16:40:38.659764Z",
     "shell.execute_reply": "2025-08-15T16:40:38.653216Z",
     "shell.execute_reply.started": "2025-08-15T16:40:38.361319Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # Visualization\n",
    "\n",
    "# Plot loss and accuracy in subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax1.set_title('Loss')\n",
    "ax2.set_title('Accuracy')\n",
    "for dataset in ('train', 'test'):\n",
    "  ax1.plot(metrics_history[f'{dataset}_loss'], label=f'{dataset}_loss')\n",
    "  ax2.plot(metrics_history[f'{dataset}_accuracy'], label=f'{dataset}_accuracy')\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
