# ML parallel practice

## üìù Notebooks

#### TPU Examples

* (Published: 2025-04-06) [Simple_NN_jax_TPU_DP_MP.ipynb](https://github.com/JLAI162/ML_parallel_practice/blob/main/Simple_NN_jax_TPU_DP_MP.ipynb) - A JAX example showcasing combined Data and Model Parallelism on TPU. It uses JAX's sharding features to parallelize both data and model parameters for TPU execution.

* (Published: 2025-04-06) [Simple_NN_jax_TPU_MP.ipynb](https://github.com/JLAI162/ML_parallel_practice/blob/main/Simple_NN_jax_TPU_MP.ipynb) - A simple neural network example implementing Model Parallelism on TPU using JAX. It utilizes JAX's sharding and NamedSharding features to partition and parallelize model's parameter for execution on TPU. 

* (Published: 2025-04-05) [Simple_NN_jax_TPU_DP.ipynb](https://github.com/JLAI162/ML_parallel_practice/blob/main/Simple_NN_jax_TPU_DP.ipynb) - A simple neural network example implementing Data Parallelism on TPU using JAX. It utilizes JAX's sharding and NamedSharding features to partition and parallelize data for execution on TPU. (Updated: 2025-04-06)
